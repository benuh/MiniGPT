{"ast":null,"code":"// ML Terminology Database for Educational Tooltips\nexport const mlTerminology = {\n  epochs: {\n    title: \"Epochs\",\n    definition: \"One complete pass through the entire training dataset.\",\n    detailed: \"During each epoch, the model sees every example in your training data exactly once. More epochs generally lead to better learning, but too many can cause overfitting.\",\n    examples: [\"5 epochs = model sees all data 5 times\", \"Typical range: 10-100 epochs\", \"Watch for loss plateauing to know when to stop\"],\n    tips: [\"Start with fewer epochs (10-20) to test quickly\", \"Monitor validation loss to prevent overfitting\", \"Use early stopping to automatically halt training\"],\n    relatedTerms: [\"batch_size\", \"learning_rate\", \"overfitting\"]\n  },\n  batch_size: {\n    title: \"Batch Size\",\n    definition: \"Number of training examples processed together before updating model weights.\",\n    detailed: \"Instead of updating the model after each example, we group examples into batches. Larger batches provide more stable gradients but require more memory.\",\n    examples: [\"Batch size 32 = process 32 examples, then update\", \"Common sizes: 16, 32, 64, 128\", \"Larger batches = more memory needed\"],\n    tips: [\"Start with 32 - good balance of speed and stability\", \"Reduce if you get out-of-memory errors\", \"Power of 2 sizes (16, 32, 64) work well with GPUs\"],\n    relatedTerms: [\"epochs\", \"learning_rate\", \"gradient_descent\"]\n  },\n  learning_rate: {\n    title: \"Learning Rate\",\n    definition: \"Controls how big steps the model takes when learning from mistakes.\",\n    detailed: \"Like the speed of learning. Too high and the model might overshoot the optimal solution. Too low and it learns very slowly or gets stuck.\",\n    examples: [\"0.001 = small, careful steps (common default)\", \"0.01 = bigger steps, faster learning\", \"0.0001 = very conservative, slow learning\"],\n    tips: [\"Start with 0.001 - works for most cases\", \"If loss jumps around wildly, reduce learning rate\", \"If learning is too slow, try increasing slightly\"],\n    relatedTerms: [\"optimizer\", \"gradient_descent\", \"loss_function\"]\n  },\n  optimizer: {\n    title: \"Optimizer\",\n    definition: \"The algorithm that adjusts model weights based on the calculated errors.\",\n    detailed: \"Different optimizers have different strategies for updating the model. Each has advantages for different types of problems.\",\n    examples: [\"Adam: Adaptive, works well for most problems\", \"SGD: Simple, reliable, good for fine-tuning\", \"AdamW: Adam with better weight decay\"],\n    tips: [\"Adam is a safe default choice\", \"SGD can work better for some vision tasks\", \"Try AdamW if you have overfitting issues\"],\n    relatedTerms: [\"learning_rate\", \"gradient_descent\", \"momentum\"]\n  },\n  temperature: {\n    title: \"Temperature\",\n    definition: \"Controls randomness in text generation. Higher = more creative, lower = more focused.\",\n    detailed: \"Temperature affects how the model chooses its next word. It's like controlling creativity vs. consistency in the model's responses.\",\n    examples: [\"0.1 = Very focused, predictable responses\", \"0.7 = Balanced creativity and coherence\", \"1.5 = Very creative, potentially chaotic\"],\n    tips: [\"0.7 is good for most conversations\", \"Use 0.1-0.3 for factual, precise answers\", \"Use 1.0+ for creative writing or brainstorming\"],\n    relatedTerms: [\"top_k\", \"sampling\", \"generation\"]\n  },\n  max_tokens: {\n    title: \"Max Tokens\",\n    definition: \"Maximum number of words/pieces the model will generate in its response.\",\n    detailed: \"Tokens are pieces of words (usually words or parts of words). This limits how long the response can be.\",\n    examples: [\"50 tokens ≈ 1-2 sentences\", \"150 tokens ≈ 1 paragraph\", \"500 tokens ≈ several paragraphs\"],\n    tips: [\"Start with 100-150 for chat responses\", \"Increase for longer, detailed answers\", \"Lower values generate responses faster\"],\n    relatedTerms: [\"temperature\", \"context_length\", \"tokenization\"]\n  },\n  loss_function: {\n    title: \"Loss Function\",\n    definition: \"Measures how wrong the model's predictions are. Training tries to minimize this.\",\n    detailed: \"The loss function calculates the difference between what the model predicted and the correct answer. Lower loss = better performance.\",\n    examples: [\"Cross-entropy loss for text prediction\", \"Mean squared error for regression\", \"Loss starts high, should decrease over time\"],\n    tips: [\"Watch loss decrease during training\", \"If loss stops improving, training might be done\", \"Sudden loss spikes might indicate learning rate too high\"],\n    relatedTerms: [\"gradient_descent\", \"backpropagation\", \"optimization\"]\n  },\n  overfitting: {\n    title: \"Overfitting\",\n    definition: \"When the model memorizes training data instead of learning general patterns.\",\n    detailed: \"Like studying for a test by memorizing specific questions instead of understanding concepts. The model does great on training data but poorly on new data.\",\n    examples: [\"Training accuracy: 99%, Test accuracy: 60% = overfitting\", \"Model gives perfect answers to training examples\", \"But struggles with slightly different questions\"],\n    tips: [\"Use validation data to detect overfitting\", \"Stop training when validation loss starts increasing\", \"Add regularization or reduce model complexity\"],\n    relatedTerms: [\"validation\", \"regularization\", \"generalization\"]\n  },\n  gradient_descent: {\n    title: \"Gradient Descent\",\n    definition: \"The fundamental algorithm that teaches the model by showing it its mistakes.\",\n    detailed: \"Like rolling a ball downhill to find the bottom of a valley. The algorithm calculates which direction reduces error the most and moves the model parameters in that direction.\",\n    examples: [\"Calculate error on current prediction\", \"Determine which weights caused the error\", \"Adjust weights to reduce future errors\"],\n    tips: [\"This happens automatically during training\", \"Learning rate controls the step size\", \"Batch size affects how smooth the descent is\"],\n    relatedTerms: [\"learning_rate\", \"optimizer\", \"backpropagation\"]\n  },\n  checkpoints: {\n    title: \"Checkpoints\",\n    definition: \"Saved snapshots of the model during training, like save points in a video game.\",\n    detailed: \"Regular saves of the model's state so you can resume training if it's interrupted, or go back to a better version if training goes wrong.\",\n    examples: [\"Save every 100 steps or every epoch\", \"Keep best performing checkpoint\", \"Resume training from last checkpoint\"],\n    tips: [\"Always enable checkpoints for long training\", \"Save to different files to avoid corruption\", \"Keep the best checkpoint even if training continues\"],\n    relatedTerms: [\"model_saving\", \"training_resume\", \"best_model\"]\n  },\n  gpu_training: {\n    title: \"GPU Training\",\n    definition: \"Using graphics cards to speed up model training by 10-100x compared to CPU.\",\n    detailed: \"GPUs have thousands of small cores perfect for the parallel calculations needed in neural networks. Much faster than CPU for training.\",\n    examples: [\"CPU training: hours to days\", \"GPU training: minutes to hours\", \"NVIDIA GPUs work best with PyTorch\"],\n    tips: [\"Enable if you have a compatible GPU\", \"Monitor GPU memory usage\", \"Reduce batch size if you get out-of-memory errors\"],\n    relatedTerms: [\"batch_size\", \"memory_usage\", \"cuda\"]\n  }\n};\n\n// Helper function to get related terms\nexport const getRelatedTerms = termKey => {\n  const term = mlTerminology[termKey];\n  if (!(term !== null && term !== void 0 && term.relatedTerms)) return [];\n  return term.relatedTerms.map(relatedKey => {\n    var _mlTerminology$relate;\n    return {\n      key: relatedKey,\n      title: ((_mlTerminology$relate = mlTerminology[relatedKey]) === null || _mlTerminology$relate === void 0 ? void 0 : _mlTerminology$relate.title) || relatedKey\n    };\n  });\n};\n\n// Helper function to search terms\nexport const searchTerms = query => {\n  const lowercaseQuery = query.toLowerCase();\n  return Object.entries(mlTerminology).filter(([key, term]) => key.toLowerCase().includes(lowercaseQuery) || term.title.toLowerCase().includes(lowercaseQuery) || term.definition.toLowerCase().includes(lowercaseQuery));\n};","map":{"version":3,"names":["mlTerminology","epochs","title","definition","detailed","examples","tips","relatedTerms","batch_size","learning_rate","optimizer","temperature","max_tokens","loss_function","overfitting","gradient_descent","checkpoints","gpu_training","getRelatedTerms","termKey","term","map","relatedKey","_mlTerminology$relate","key","searchTerms","query","lowercaseQuery","toLowerCase","Object","entries","filter","includes"],"sources":["/Users/benjaminhu/Desktop/Benjamin/Projects/Github/MiniGPT/frontend/src/data/mlTerminology.js"],"sourcesContent":["// ML Terminology Database for Educational Tooltips\nexport const mlTerminology = {\n  epochs: {\n    title: \"Epochs\",\n    definition: \"One complete pass through the entire training dataset.\",\n    detailed: \"During each epoch, the model sees every example in your training data exactly once. More epochs generally lead to better learning, but too many can cause overfitting.\",\n    examples: [\n      \"5 epochs = model sees all data 5 times\",\n      \"Typical range: 10-100 epochs\",\n      \"Watch for loss plateauing to know when to stop\"\n    ],\n    tips: [\n      \"Start with fewer epochs (10-20) to test quickly\",\n      \"Monitor validation loss to prevent overfitting\",\n      \"Use early stopping to automatically halt training\"\n    ],\n    relatedTerms: [\"batch_size\", \"learning_rate\", \"overfitting\"]\n  },\n\n  batch_size: {\n    title: \"Batch Size\",\n    definition: \"Number of training examples processed together before updating model weights.\",\n    detailed: \"Instead of updating the model after each example, we group examples into batches. Larger batches provide more stable gradients but require more memory.\",\n    examples: [\n      \"Batch size 32 = process 32 examples, then update\",\n      \"Common sizes: 16, 32, 64, 128\",\n      \"Larger batches = more memory needed\"\n    ],\n    tips: [\n      \"Start with 32 - good balance of speed and stability\",\n      \"Reduce if you get out-of-memory errors\",\n      \"Power of 2 sizes (16, 32, 64) work well with GPUs\"\n    ],\n    relatedTerms: [\"epochs\", \"learning_rate\", \"gradient_descent\"]\n  },\n\n  learning_rate: {\n    title: \"Learning Rate\",\n    definition: \"Controls how big steps the model takes when learning from mistakes.\",\n    detailed: \"Like the speed of learning. Too high and the model might overshoot the optimal solution. Too low and it learns very slowly or gets stuck.\",\n    examples: [\n      \"0.001 = small, careful steps (common default)\",\n      \"0.01 = bigger steps, faster learning\",\n      \"0.0001 = very conservative, slow learning\"\n    ],\n    tips: [\n      \"Start with 0.001 - works for most cases\",\n      \"If loss jumps around wildly, reduce learning rate\",\n      \"If learning is too slow, try increasing slightly\"\n    ],\n    relatedTerms: [\"optimizer\", \"gradient_descent\", \"loss_function\"]\n  },\n\n  optimizer: {\n    title: \"Optimizer\",\n    definition: \"The algorithm that adjusts model weights based on the calculated errors.\",\n    detailed: \"Different optimizers have different strategies for updating the model. Each has advantages for different types of problems.\",\n    examples: [\n      \"Adam: Adaptive, works well for most problems\",\n      \"SGD: Simple, reliable, good for fine-tuning\",\n      \"AdamW: Adam with better weight decay\"\n    ],\n    tips: [\n      \"Adam is a safe default choice\",\n      \"SGD can work better for some vision tasks\",\n      \"Try AdamW if you have overfitting issues\"\n    ],\n    relatedTerms: [\"learning_rate\", \"gradient_descent\", \"momentum\"]\n  },\n\n  temperature: {\n    title: \"Temperature\",\n    definition: \"Controls randomness in text generation. Higher = more creative, lower = more focused.\",\n    detailed: \"Temperature affects how the model chooses its next word. It's like controlling creativity vs. consistency in the model's responses.\",\n    examples: [\n      \"0.1 = Very focused, predictable responses\",\n      \"0.7 = Balanced creativity and coherence\",\n      \"1.5 = Very creative, potentially chaotic\"\n    ],\n    tips: [\n      \"0.7 is good for most conversations\",\n      \"Use 0.1-0.3 for factual, precise answers\",\n      \"Use 1.0+ for creative writing or brainstorming\"\n    ],\n    relatedTerms: [\"top_k\", \"sampling\", \"generation\"]\n  },\n\n  max_tokens: {\n    title: \"Max Tokens\",\n    definition: \"Maximum number of words/pieces the model will generate in its response.\",\n    detailed: \"Tokens are pieces of words (usually words or parts of words). This limits how long the response can be.\",\n    examples: [\n      \"50 tokens ≈ 1-2 sentences\",\n      \"150 tokens ≈ 1 paragraph\",\n      \"500 tokens ≈ several paragraphs\"\n    ],\n    tips: [\n      \"Start with 100-150 for chat responses\",\n      \"Increase for longer, detailed answers\",\n      \"Lower values generate responses faster\"\n    ],\n    relatedTerms: [\"temperature\", \"context_length\", \"tokenization\"]\n  },\n\n  loss_function: {\n    title: \"Loss Function\",\n    definition: \"Measures how wrong the model's predictions are. Training tries to minimize this.\",\n    detailed: \"The loss function calculates the difference between what the model predicted and the correct answer. Lower loss = better performance.\",\n    examples: [\n      \"Cross-entropy loss for text prediction\",\n      \"Mean squared error for regression\",\n      \"Loss starts high, should decrease over time\"\n    ],\n    tips: [\n      \"Watch loss decrease during training\",\n      \"If loss stops improving, training might be done\",\n      \"Sudden loss spikes might indicate learning rate too high\"\n    ],\n    relatedTerms: [\"gradient_descent\", \"backpropagation\", \"optimization\"]\n  },\n\n  overfitting: {\n    title: \"Overfitting\",\n    definition: \"When the model memorizes training data instead of learning general patterns.\",\n    detailed: \"Like studying for a test by memorizing specific questions instead of understanding concepts. The model does great on training data but poorly on new data.\",\n    examples: [\n      \"Training accuracy: 99%, Test accuracy: 60% = overfitting\",\n      \"Model gives perfect answers to training examples\",\n      \"But struggles with slightly different questions\"\n    ],\n    tips: [\n      \"Use validation data to detect overfitting\",\n      \"Stop training when validation loss starts increasing\",\n      \"Add regularization or reduce model complexity\"\n    ],\n    relatedTerms: [\"validation\", \"regularization\", \"generalization\"]\n  },\n\n  gradient_descent: {\n    title: \"Gradient Descent\",\n    definition: \"The fundamental algorithm that teaches the model by showing it its mistakes.\",\n    detailed: \"Like rolling a ball downhill to find the bottom of a valley. The algorithm calculates which direction reduces error the most and moves the model parameters in that direction.\",\n    examples: [\n      \"Calculate error on current prediction\",\n      \"Determine which weights caused the error\",\n      \"Adjust weights to reduce future errors\"\n    ],\n    tips: [\n      \"This happens automatically during training\",\n      \"Learning rate controls the step size\",\n      \"Batch size affects how smooth the descent is\"\n    ],\n    relatedTerms: [\"learning_rate\", \"optimizer\", \"backpropagation\"]\n  },\n\n  checkpoints: {\n    title: \"Checkpoints\",\n    definition: \"Saved snapshots of the model during training, like save points in a video game.\",\n    detailed: \"Regular saves of the model's state so you can resume training if it's interrupted, or go back to a better version if training goes wrong.\",\n    examples: [\n      \"Save every 100 steps or every epoch\",\n      \"Keep best performing checkpoint\",\n      \"Resume training from last checkpoint\"\n    ],\n    tips: [\n      \"Always enable checkpoints for long training\",\n      \"Save to different files to avoid corruption\",\n      \"Keep the best checkpoint even if training continues\"\n    ],\n    relatedTerms: [\"model_saving\", \"training_resume\", \"best_model\"]\n  },\n\n  gpu_training: {\n    title: \"GPU Training\",\n    definition: \"Using graphics cards to speed up model training by 10-100x compared to CPU.\",\n    detailed: \"GPUs have thousands of small cores perfect for the parallel calculations needed in neural networks. Much faster than CPU for training.\",\n    examples: [\n      \"CPU training: hours to days\",\n      \"GPU training: minutes to hours\",\n      \"NVIDIA GPUs work best with PyTorch\"\n    ],\n    tips: [\n      \"Enable if you have a compatible GPU\",\n      \"Monitor GPU memory usage\",\n      \"Reduce batch size if you get out-of-memory errors\"\n    ],\n    relatedTerms: [\"batch_size\", \"memory_usage\", \"cuda\"]\n  }\n};\n\n// Helper function to get related terms\nexport const getRelatedTerms = (termKey) => {\n  const term = mlTerminology[termKey];\n  if (!term?.relatedTerms) return [];\n\n  return term.relatedTerms.map(relatedKey => ({\n    key: relatedKey,\n    title: mlTerminology[relatedKey]?.title || relatedKey\n  }));\n};\n\n// Helper function to search terms\nexport const searchTerms = (query) => {\n  const lowercaseQuery = query.toLowerCase();\n  return Object.entries(mlTerminology).filter(([key, term]) =>\n    key.toLowerCase().includes(lowercaseQuery) ||\n    term.title.toLowerCase().includes(lowercaseQuery) ||\n    term.definition.toLowerCase().includes(lowercaseQuery)\n  );\n};"],"mappings":"AAAA;AACA,OAAO,MAAMA,aAAa,GAAG;EAC3BC,MAAM,EAAE;IACNC,KAAK,EAAE,QAAQ;IACfC,UAAU,EAAE,wDAAwD;IACpEC,QAAQ,EAAE,wKAAwK;IAClLC,QAAQ,EAAE,CACR,wCAAwC,EACxC,8BAA8B,EAC9B,gDAAgD,CACjD;IACDC,IAAI,EAAE,CACJ,iDAAiD,EACjD,gDAAgD,EAChD,mDAAmD,CACpD;IACDC,YAAY,EAAE,CAAC,YAAY,EAAE,eAAe,EAAE,aAAa;EAC7D,CAAC;EAEDC,UAAU,EAAE;IACVN,KAAK,EAAE,YAAY;IACnBC,UAAU,EAAE,+EAA+E;IAC3FC,QAAQ,EAAE,yJAAyJ;IACnKC,QAAQ,EAAE,CACR,kDAAkD,EAClD,+BAA+B,EAC/B,qCAAqC,CACtC;IACDC,IAAI,EAAE,CACJ,qDAAqD,EACrD,wCAAwC,EACxC,mDAAmD,CACpD;IACDC,YAAY,EAAE,CAAC,QAAQ,EAAE,eAAe,EAAE,kBAAkB;EAC9D,CAAC;EAEDE,aAAa,EAAE;IACbP,KAAK,EAAE,eAAe;IACtBC,UAAU,EAAE,qEAAqE;IACjFC,QAAQ,EAAE,2IAA2I;IACrJC,QAAQ,EAAE,CACR,+CAA+C,EAC/C,sCAAsC,EACtC,2CAA2C,CAC5C;IACDC,IAAI,EAAE,CACJ,yCAAyC,EACzC,mDAAmD,EACnD,kDAAkD,CACnD;IACDC,YAAY,EAAE,CAAC,WAAW,EAAE,kBAAkB,EAAE,eAAe;EACjE,CAAC;EAEDG,SAAS,EAAE;IACTR,KAAK,EAAE,WAAW;IAClBC,UAAU,EAAE,0EAA0E;IACtFC,QAAQ,EAAE,6HAA6H;IACvIC,QAAQ,EAAE,CACR,8CAA8C,EAC9C,6CAA6C,EAC7C,sCAAsC,CACvC;IACDC,IAAI,EAAE,CACJ,+BAA+B,EAC/B,2CAA2C,EAC3C,0CAA0C,CAC3C;IACDC,YAAY,EAAE,CAAC,eAAe,EAAE,kBAAkB,EAAE,UAAU;EAChE,CAAC;EAEDI,WAAW,EAAE;IACXT,KAAK,EAAE,aAAa;IACpBC,UAAU,EAAE,uFAAuF;IACnGC,QAAQ,EAAE,qIAAqI;IAC/IC,QAAQ,EAAE,CACR,2CAA2C,EAC3C,yCAAyC,EACzC,0CAA0C,CAC3C;IACDC,IAAI,EAAE,CACJ,oCAAoC,EACpC,0CAA0C,EAC1C,gDAAgD,CACjD;IACDC,YAAY,EAAE,CAAC,OAAO,EAAE,UAAU,EAAE,YAAY;EAClD,CAAC;EAEDK,UAAU,EAAE;IACVV,KAAK,EAAE,YAAY;IACnBC,UAAU,EAAE,yEAAyE;IACrFC,QAAQ,EAAE,yGAAyG;IACnHC,QAAQ,EAAE,CACR,2BAA2B,EAC3B,0BAA0B,EAC1B,iCAAiC,CAClC;IACDC,IAAI,EAAE,CACJ,uCAAuC,EACvC,uCAAuC,EACvC,wCAAwC,CACzC;IACDC,YAAY,EAAE,CAAC,aAAa,EAAE,gBAAgB,EAAE,cAAc;EAChE,CAAC;EAEDM,aAAa,EAAE;IACbX,KAAK,EAAE,eAAe;IACtBC,UAAU,EAAE,kFAAkF;IAC9FC,QAAQ,EAAE,uIAAuI;IACjJC,QAAQ,EAAE,CACR,wCAAwC,EACxC,mCAAmC,EACnC,6CAA6C,CAC9C;IACDC,IAAI,EAAE,CACJ,qCAAqC,EACrC,iDAAiD,EACjD,0DAA0D,CAC3D;IACDC,YAAY,EAAE,CAAC,kBAAkB,EAAE,iBAAiB,EAAE,cAAc;EACtE,CAAC;EAEDO,WAAW,EAAE;IACXZ,KAAK,EAAE,aAAa;IACpBC,UAAU,EAAE,8EAA8E;IAC1FC,QAAQ,EAAE,4JAA4J;IACtKC,QAAQ,EAAE,CACR,0DAA0D,EAC1D,kDAAkD,EAClD,iDAAiD,CAClD;IACDC,IAAI,EAAE,CACJ,2CAA2C,EAC3C,sDAAsD,EACtD,+CAA+C,CAChD;IACDC,YAAY,EAAE,CAAC,YAAY,EAAE,gBAAgB,EAAE,gBAAgB;EACjE,CAAC;EAEDQ,gBAAgB,EAAE;IAChBb,KAAK,EAAE,kBAAkB;IACzBC,UAAU,EAAE,8EAA8E;IAC1FC,QAAQ,EAAE,gLAAgL;IAC1LC,QAAQ,EAAE,CACR,uCAAuC,EACvC,0CAA0C,EAC1C,wCAAwC,CACzC;IACDC,IAAI,EAAE,CACJ,4CAA4C,EAC5C,sCAAsC,EACtC,8CAA8C,CAC/C;IACDC,YAAY,EAAE,CAAC,eAAe,EAAE,WAAW,EAAE,iBAAiB;EAChE,CAAC;EAEDS,WAAW,EAAE;IACXd,KAAK,EAAE,aAAa;IACpBC,UAAU,EAAE,iFAAiF;IAC7FC,QAAQ,EAAE,2IAA2I;IACrJC,QAAQ,EAAE,CACR,qCAAqC,EACrC,iCAAiC,EACjC,sCAAsC,CACvC;IACDC,IAAI,EAAE,CACJ,6CAA6C,EAC7C,6CAA6C,EAC7C,qDAAqD,CACtD;IACDC,YAAY,EAAE,CAAC,cAAc,EAAE,iBAAiB,EAAE,YAAY;EAChE,CAAC;EAEDU,YAAY,EAAE;IACZf,KAAK,EAAE,cAAc;IACrBC,UAAU,EAAE,6EAA6E;IACzFC,QAAQ,EAAE,wIAAwI;IAClJC,QAAQ,EAAE,CACR,6BAA6B,EAC7B,gCAAgC,EAChC,oCAAoC,CACrC;IACDC,IAAI,EAAE,CACJ,qCAAqC,EACrC,0BAA0B,EAC1B,mDAAmD,CACpD;IACDC,YAAY,EAAE,CAAC,YAAY,EAAE,cAAc,EAAE,MAAM;EACrD;AACF,CAAC;;AAED;AACA,OAAO,MAAMW,eAAe,GAAIC,OAAO,IAAK;EAC1C,MAAMC,IAAI,GAAGpB,aAAa,CAACmB,OAAO,CAAC;EACnC,IAAI,EAACC,IAAI,aAAJA,IAAI,eAAJA,IAAI,CAAEb,YAAY,GAAE,OAAO,EAAE;EAElC,OAAOa,IAAI,CAACb,YAAY,CAACc,GAAG,CAACC,UAAU;IAAA,IAAAC,qBAAA;IAAA,OAAK;MAC1CC,GAAG,EAAEF,UAAU;MACfpB,KAAK,EAAE,EAAAqB,qBAAA,GAAAvB,aAAa,CAACsB,UAAU,CAAC,cAAAC,qBAAA,uBAAzBA,qBAAA,CAA2BrB,KAAK,KAAIoB;IAC7C,CAAC;EAAA,CAAC,CAAC;AACL,CAAC;;AAED;AACA,OAAO,MAAMG,WAAW,GAAIC,KAAK,IAAK;EACpC,MAAMC,cAAc,GAAGD,KAAK,CAACE,WAAW,CAAC,CAAC;EAC1C,OAAOC,MAAM,CAACC,OAAO,CAAC9B,aAAa,CAAC,CAAC+B,MAAM,CAAC,CAAC,CAACP,GAAG,EAAEJ,IAAI,CAAC,KACtDI,GAAG,CAACI,WAAW,CAAC,CAAC,CAACI,QAAQ,CAACL,cAAc,CAAC,IAC1CP,IAAI,CAAClB,KAAK,CAAC0B,WAAW,CAAC,CAAC,CAACI,QAAQ,CAACL,cAAc,CAAC,IACjDP,IAAI,CAACjB,UAAU,CAACyB,WAAW,CAAC,CAAC,CAACI,QAAQ,CAACL,cAAc,CACvD,CAAC;AACH,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}